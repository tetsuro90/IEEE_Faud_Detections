[np.nanとNone]
feather形式だとnp.nanをシリアラズして、読み込んだ時はNoneになってしまう（object型の時のみ）
元のデータ（例えば、R_emaildomain_1）にはnp.nanとNoneが混在しているが、feather形式の場合はnp.nanしかないので
labelencoderの時に変数化される個数が変わってくる。
 
[features]
Nullの個数はあまり効かなかった。fraudとnonfraudでは分布は異なる。
もう一工夫必要？

TransactionAmtのlogを取ると結構効いた

TransactionDTはあまり効かない。時差を考慮出来ていない？？

count_encodingはかなり効く

Targetencoding:leakが怖い。ひとまず使用はしないでおく。

category_m_sum_nanは確実に効いている（NaNの方が重要？⇨カテゴリタイプ毎のNaNの数は重要かも）。

transaction_amt_mean_stdは確実に効いてる。
特に　card１

[省メモリ化】
reduce_mem_usage()関数を用いてもほとんど時間短縮にはならず。
省メモリ化したデータをシリアライズしておけば読み込みが早くなるかも？？


【パラメータチューニング】
過学習抑制は大事。
early_stoppingで設定していたとしてもなかなか止まらない場合は
かなりの確率で過学習している。

[validation]
Kfoldの方がCVもLBも高いが、CVとLBの乖離が大きい。
timeseriessplitの方が信頼性は高い？？
Predictionの分布は確認しておいたほうが良い。


